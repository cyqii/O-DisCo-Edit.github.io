<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Given a video and a text prompt, Dreamix edits the video while maintaining fidelity to color, posture, object size and camera pose, resulting in a temporally consistent video.">
  <meta property="og:title" content="Dreamix: Video Diffusion Models are General Video Editors"/>
  <meta property="og:description" content="Given a video and a text prompt, Dreamix edits the video while maintaining fidelity to color, posture, object size and camera pose, resulting in a temporally consistent video."/>
  <meta property="og:url" content="https://dreamix-video-editing.github.io"/>
  <meta property="og:image" content="static/image/og_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Dreamix: Video Diffusion Models are General Video Editors">
  <meta name="twitter:description" content="Given a video and a text prompt, Dreamix edits the video while maintaining fidelity to color, posture, object size and camera pose, resulting in a temporally consistent video.">
  <meta name="twitter:image" content="static/images/twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="Video diffusion models, video editing, dreamix, dreambooth, imagen-video">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>AVATAR: Autonomous Vehicle Assessment through Testing of Adversarial Patches in Real-time</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AVATAR: Autonomous Vehicle Assessment through Testing of Adversarial Patches in Real-time</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://sharmaabhijith.github.io" target="_blank">Abhijith Sharma</a><sup>*,1</sup>,
              </span>
              <span class="author-block">
                <a href="https://space.uwo.ca/people/our-members/narayan-apurva/index.html" target="_blank">Apurva Narayan</a><sup>†,2</sup>,
              </span>
              <span class="author-block">
                <a href="https://uwaterloo.ca/automation-intelligent-systems-group/profiles/nasser-lashgarian-azad" target="_blank">Nasser Azad</a><sup>†,1</sup>,
              </span>
              <span class="author-block">
                <a href="https://uwaterloo.ca/electrical-computer-engineering/profile/sfischme" target="_blank"></a>Sebastian Fischmeister<sup>†,1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/stefan-marksteiner-332a4184?originalSubdomain=at" target="_blank"></a>Stefan Marksteiner<sup>3</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of Waterloo,</span>
              <span class="author-block"><sup>2</sup>Western University,</span>
              <span class="author-block"><sup>3</sup>AVL, Graz Austria</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Main Author, <sup>†</sup>Indicates Equal Advising</small></span>
              <span class="eql-cntrb"><small></small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://www.techrxiv.org/doi/full/10.36227/techrxiv.172165647.71183157/v2" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>



            <!-- ArXiv abstract Link -->
            <span class="link-block">
              <a href="https://ieeexplore.ieee.org/abstract/document/10646575/" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>IEEE TIV</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>








<!-- Subject Driven Video Generation carousel -->
<section class="hero teaser">
      <div class="hero-body ">
    <div class="container is-max-desktop">
  
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="header-video1" autoplay muted loop playsinline height="100%" src="static/videos/banner_video.mp4">
          </video>
          <h2 class="subtitle has-text-centered">
        Given a video and a text prompt, Dreamix edits the video while maintaining fidelity to color, posture, object size and camera pose, resulting in a temporally consistent video. Here, Dreamix turns the eating monkey (left) to a dancing bear (right) given the prompt “A bear dancing and jumping to upbeat music, moving his whole body“.
      </h2>
        </div>
        <div class="item item-video2">
          <video poster="" id="header-video2" autoplay muted loop playsinline height="100%" src="static/videos/img2vid_turtle.mp4">
          </video>
          <h2 class="subtitle has-text-centered">
        Dreamix can create videos based on image and text inputs. In this example it is able to instill complex motion in a static image, adding a moving shark and making the turtle swim. In this case, visual fidelity to object location and background was preserved but the turtle direction was flipped.
      </h2>
        </div>
        <div class="item item-video3">
          <video poster="" id="header-video3" autoplay muted loop playsinline height="100%"  src="static/videos/subj_driv_lifting.mp4">
          </video>
          <h2 class="subtitle has-text-centered">
          Given a small collection of images showing the same subject, Dreamix can generate new videos with the subject in motion. In this example, given a small number of images of the toy fireman, Dreamix is able to extract the visual features then animate it to lift weights while maintaining fidelity and temporal consistency.
      </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Subject Driven Video Generation carousel -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Autonomy in vehicles is achieved using AI for
            control and perception tasks. The visual inputs from camera
            forms the foundation for subsequent control that follows. Existing
            works have shown adversarial vulnerabilities during AI based
            visual tasks. One major threat is adversarial patches, which can
            impact decision making in autonomous vehicles (AVs). Current
            evaluation methods often utilize static datasets with unrealistic
            patch placements. This paper proposes a novel framework,
            AVATAR, to standardize adversarial patch testing and analysis.
            AVATAR creates a simulation environment, where the patch is
            integrated with actors in the scene to enhance realism during
            testing. The vehicle’s behaviour is captured as a time-series
            trace for post-simulation quantitative analysis. Furthermore, we
            introduce an Adversarial Trace Classifier (ATC) that analyzes
            these traces to predict the potential presence of adversarial
            patches. The aim is to detect vulnerabilities in object detection
            algorithms for the design of robust perception system for AVs.
            Hence, AVATAR will pave the way for safer deployment of
            autonomous vehicles in real-world.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero is-small is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">AVATAR Block Diagram</h2>
          <center>
          <img src="static/images/avatar_block_diagram.png" alt="Block Diagram" class="center-image blend-img-background"/>
          </center>
          <div class="level-set has-text-justified">
            <br>
            <p>
              The AVATAR framework is a step toward Level 3 of the adversarial testing paradigm, replicating real-world conditions for testing AVs. It provides an abstraction over the CARLA PythonAPI Client, with a Tkinter-based GUI featuring four components: CARLA Server Configuration (connects the server, sets SEED, mode, and FPS), CARLA World Setting (configures resolution, town, weather, pedestrians, and vehicles), CARLA Actor Setting (sets car model, agent type/behavior, and detection model), and Adversarial Attack Setting (chooses attack type, magnitude, and patch placement on vehicles or billboards). AVATAR enhances adversarial patch testing for autonomous vehicles, ensuring realistic, reproducible, and customizable simulations.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Adversarial Testing Paradigm</h2>
          <center>
          <img src="static/images/adversarial_test_paradigm.png" alt="Inference Overview" class="center-image"/>
          </center>
          <div class="level-set has-text-justified">
            <br>
            <p>
              Figure illustrates the adversarial test paradigm levels. Level 1 applies patches offline to image datasets for object detection, dominating existing research but lacking realism. Level 2 introduces more realistic scenarios by analyzing recorded attacked image frames but lacks real-time validation. Level 3 addresses this gap by enabling real-time adversarial testing within simulation environments, crucial for autonomous vehicle evaluation and often overlooked in existing studies.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">AVATAR GUI in CARLA</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <div class="publication-video" style="display: inline-block; transform: scale(0.8); transform-origin: top center;">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/g-AqOTro-fY?si=7q17FKDAFmSDrECI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Real World Demonstration</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/5MRjvLdCy-M?si=sMjHCzATN27iWJru" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->



<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{sharma2024avatar,
      title={AVATAR: Autonomous Vehicle Assessment through Testing of Adversarial Patches in Real-time},
      author={Sharma, Abhijith and Narayan, Apurva and Azad, Nasser Lashgarian and Fischmeister, Sebastian and Marksteiner, Stefan},
      journal={IEEE Transactions on Intelligent Vehicles},
      year={2024},
      publisher={IEEE}
    }
</code></pre>
  </div>
</section>
<!-- End BibTex citation -->

<!--Acknowledgements -->
<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    We extend our gratitude to the members of the <a href="https://uwaterloo.ca/embedded-software-group/" target="_blank">Real-time Embedded Software Group</a>@ UWaterloo for their invaluable insights, critical brainstorming sessions, and innovative ideas that greatly contributed to this work.
  </div>
</section>
<!--End Acknowledgements -->
  
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

<!-- Default Statcounter code for Dreamix
https://dreamix-video-editing.github.io -->
<script type="text/javascript">
var sc_project=12843789; 
var sc_invisible=1; 
var sc_security="e9c3bf5f"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12843789/0/e9c3bf5f/1/"
alt="Web Analytics"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>

<!-- End of Statcounter Code -->

</body>
</html>
